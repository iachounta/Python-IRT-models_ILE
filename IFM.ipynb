{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06e0e1f5-2f8a-4770-95de-75c8bae8deab",
   "metadata": {},
   "source": [
    "# Instructional Factors Analysis Model (IFM) Implementation\n",
    "This notebook provides a python implementation of the IFM student model.\n",
    "The PFM model calculates the probability of a student carrying out correctly a step based on the prior correct and incorrect attempts (opportunities) as well as the tells (hints) that a student received from the intelligent tutor.\n",
    "\n",
    "Please edit and execute the implementation steps taking into account what we learned about the rule space student models and the Q-matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724163ce-b215-4896-8cf6-ebc7c376c530",
   "metadata": {},
   "source": [
    "## Initializing the environment\n",
    "First, we import the required libraries for handling data and training the machine learning model. We deactivate potential warnings for readability purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3684a1de-a3f5-4a30-8981-ab451c96a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from patsy import dmatrices\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, brier_score_loss\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dbe604-e9fc-4317-90db-3dd30083a6df",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "We define the function **feature_engineering()** that transforms the student data values into the appropriate types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89788a8a-5cfe-4351-a5b7-7029f79ca0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    " def feature_engineering(df):\n",
    "    df.loc[ df['First Attempt'] == 'incorrect', 'First Attempt'] = 0\n",
    "    df.loc[ df['First Attempt'] == 'hint', 'First Attempt'] = 0\n",
    "    df.loc[ df['First Attempt'] == 'correct', 'First Attempt'] = 1\n",
    "    df = df[(df['First Attempt']==0) | (df['First Attempt']==1)]\n",
    "\n",
    "    df=df.dropna()\n",
    "    df.insert(loc=len(df.columns),column='Outcome',value=df['First Attempt'])\n",
    "\n",
    "    df.rename(columns={'KC (Default)': 'KCModel', 'Opportunity': 'OpportunityModel'}, inplace=True)\n",
    "\n",
    "    df.rename(columns={'Corrects': 'CorrectModel', 'Incorrects': 'IncorrectModel'}, inplace=True)\n",
    "\n",
    "    df.rename(columns={'Hints': 'TellsModel'}, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4514b004-21ac-421c-bb3d-77eb76f5e7dc",
   "metadata": {},
   "source": [
    "## Model Training and Testing\n",
    "For the model's implementation, we will use Logistic Regression and the python library scikit-learn.\n",
    "The function **trainModel()** splits the dataset into a training and a test dataset following the 80/20 (Paretto) principle.\n",
    "Then, we use the \"train\" subset to train the model and the \"test\" subset to test the model.\n",
    "\n",
    "The prediction values are stored in the variable *\"y_pred\"* while the actual values are stored in the variable *\"y_test\"*.\n",
    "By comparing the variables *\"y_pred\"* and *\"y_test\"*, we can assess the performance of the predictive model.\n",
    "To do so, we use the following measures: RMSE, f1, precision and recall since our model practically works as a binary classifier to predict correct or incorrect student steps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bdbcd1-0d3e-4ba7-839c-3d9a168b23f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(df,modeltype,X):\n",
    "\n",
    "    y = df['Outcome']\n",
    "    y= y.astype('int')\n",
    "\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    TrainTestSplitModel=LogisticRegression(max_iter=1000,penalty='l2')   ######  USUALLY L2\n",
    "    TrainTestSplitModel.fit(X_train,y_train)\n",
    "\n",
    "    y_pred=TrainTestSplitModel.predict(X_test)\n",
    "    RMSE=np.sqrt(np.mean((y_test-y_pred)**2))\n",
    "    f1=f1_score(y_test, y_pred, average=\"macro\")\n",
    "    precision=precision_score(y_test, y_pred, average=\"macro\")\n",
    "    recall=recall_score(y_test, y_pred, average=\"macro\")    \n",
    "\n",
    "    return (RMSE, f1, precision, recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c808477b-9d23-46a3-a801-156e3d9b02ee",
   "metadata": {},
   "source": [
    "## Read data\n",
    "Now, lets import an example dataset which we will use for training and testing the model.\n",
    "First, we read the dataset from the excel file \"Example\" and we save it as a pandas dataframe.\n",
    "\n",
    "Then, we call the function **feature_engineering()** to pre-process and prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5834614f-4b69-4892-96da-48693d8d99be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "datalink = \"https://drive.google.com/uc?export=download&id=1kyb9X7rcN5hObMkp9cuQ1E0TNb6nXz-U\"\n",
    "xl = pd.ExcelFile(datalink)\n",
    "df = xl.parse(\"Example\")\n",
    "df.head()\n",
    "\n",
    "#transform data\n",
    "data = feature_engineering(df)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d4ea5c-124b-4fe0-901a-bfcd245eeead",
   "metadata": {},
   "source": [
    "## Define the model's function\n",
    "\n",
    "Your task is to define the logistic regression function for the IFM model. Remember, the IFM model calculates the probability of correctness based on the student's prior correct and incorrect responses as well as the tells (hints) that a student receives from the tutor in the respective Knowledge Components (KCs).\n",
    "\n",
    "The function **dmatrices()** prepares the X(input) and y(output) data that we will use for training and testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c4831b-a4a6-4fd3-9b2d-c1c872366132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify the model type\n",
    "modeltype=\"IFM\"\n",
    "#specify the model function. Here you should complete the function for the IFM model as previously done for the AFM and the PFM\n",
    "y, X = dmatrices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b3977b-18b5-4b34-b494-23342f752ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "(RMSE, f1, precision, recall)=trainModel(data,modeltype,X)\n",
    "print(RMSE, f1, precision, recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3ada87-de2a-4ab4-bfc6-fcbd69a26967",
   "metadata": {},
   "source": [
    "**QUESTION 1:**\n",
    "How do the results (RMSE, f1, precision, recall) change if you train the model on a new extended dataset?\n",
    "The dataset can be retrieved at: https://drive.google.com/uc?export=download&id=12Xu21Tbp-1O-4fevB_fXAj_JWvoJU5Jl\n",
    "\n",
    "Please change the code below so that you use the new dataset for the training and testing of the model and don't forget to also define the IFM function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f4a7ac-87e9-4013-beb9-cb4af10ddc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "datalink = \"\"\n",
    "xl = pd.ExcelFile(datalink)\n",
    "df = xl.parse(\"Example\")\n",
    "df.head()\n",
    "\n",
    "#transform data\n",
    "data = feature_engineering(df)\n",
    "data.head()\n",
    "\n",
    "#specify the model type\n",
    "modeltype=\"IFM\"\n",
    "#specify the model function. Here you should complete the function for the IFM model as previously done for the AFM and the PFM\n",
    "y, X = dmatrices()\n",
    "\n",
    "(RMSE, f1, precision, recall)=trainModel(data,modeltype,X)\n",
    "print(RMSE, f1, precision, recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fac01ea-86c9-4218-9f8c-d9d049024443",
   "metadata": {},
   "source": [
    "**QUESTION 2:** How do the results compare to the results you got from the AFM and the PFM models earlier?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
